// Copyright (C) 2011 by Christoph Hack. All rights reserved.
// Use of this source code is governed by the New BSD License.
/*
   This program contains a simple micro-benchmark for a Disruptor [1] like
   event buffer (or at least what I think that Disruptor might be). There
   isn't any kind of API yet and this test is currently limited to a
   single producer - single consumer architecture, but generally the architecture of Disruptor is also well suited for multiple producers and consumers.

   According to the technical paper about Disruptor [2] it's design has
   several benefits over traditional message queues. Some of the
   highlights are:

   * Preallocated Ring Buffers are faster than Single Linked Lists because
   they can utilize the caches better and they produce no garbage.

   * The lock free implementation avoids context switches which might lead
   the queue to be rescheduled on another core with an empty cache.

   * Producers and consumers will start to batch event messaging / receiving
   as soon as they fall behind. This avoids some synchronization overhead.

   * Disrupter like message buffers can be used in interesting architectures,
   like that one from LMAX [3]. The full article can be found here [4].

   Disclaimer: I haven't done any other concurrent programs yet, and i doubt
   that the implementation is correct. So please have patience.

   [1]: http://code.google.com/p/disruptor/
   [2]: http://disruptor.googlecode.com/files/Disruptor-1.0.pdf
   [3]: http://martinfowler.com/articles/images/lmax/arch-full.png
   [4]: http://martinfowler.com/articles/lmax.html
*/
package main

import (
	"fmt"
	"runtime"
	"sync/atomic"
	"time"
)

const Iterations = 10000000
const BufferSize = 2048
const BufferMask = BufferSize - 1

func BenchmarkMyDisruptor() {
	var ring [BufferSize]int // the ring buffer
	var cseq, pseq uint64    // consumer and producer sequence number

	go func() { // producer goroutine
		var max_seq uint64
		for seq := uint64(0); seq < Iterations; seq++ {
			// busy spin until there is room for writing
			for seq >= max_seq {
				max_seq = atomic.LoadUint64(&cseq) + BufferSize - 2
			}
			// send the message
			ring[seq&BufferMask] = int(seq)
			atomic.StoreUint64(&pseq, seq+1) // Better: LazyStoreUint64
		}
	}()

	var max_seq uint64
	for seq := uint64(0); seq < Iterations; seq++ {
		// busy spin until there is data available
		for seq >= max_seq {
			max_seq = atomic.LoadUint64(&pseq)
		}

		// data can now be read from ring[seq&2047]
		// XXX: read and writes to the ring are properly synchronized, but are
		// all changes to the ring guaranteed to be visible here?
		val := ring[seq&BufferMask]
		atomic.StoreUint64(&cseq, seq) // Better: LazyStoreUint64()

		if val != int(seq) {
			panic("invalid result")
		}
	}
}

func main() {
	runtime.GOMAXPROCS(2)
	var start time.Time
	var finish time.Time
	start = time.Now()
	BenchmarkMyDisruptor()
	finish = time.Now()
	fmt.Println(finish.Sub(start).Nanoseconds() / 10000000)
}
